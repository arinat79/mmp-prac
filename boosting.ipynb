{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение, ММП ВМК МГУ\n",
    "\n",
    "## Практическое задание 4. Разложение ошибки на смещение и разброс. Градиентный бустинг ~~своими руками~~\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "Дата выдачи: 09.12.2019\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 22.12.2019\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 29.12.2019\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-06-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке\n",
    "\n",
    "### О задании\n",
    "\n",
    "В этом задании вам предстоит воспользоваться возможностями bootstraping для оценки смещения и разброса алгоритмов машинного обучения. Делать мы это будем на данных boston. \n",
    "Также в задании вам будет предложено пообучать готовые модели градиентного бустинга и CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Bias-Variance Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston[\"data\"]\n",
    "y = boston[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506,))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вычисление bias и variance с помощью бутстрапа\n",
    "На лекции была выведено следующая формула, показывающая, как можно представить ошибку алгоритма регрессии в виде суммы трех компонент:\n",
    "$$\n",
    "L(\\mu) = \n",
    "    \\mathbb{E}_{x, y}\\bigl[\\mathbb{E}_{X}\\bigl[ (y - \\mu(X)(x))^2 \\bigr]\\bigr] = \n",
    "$$\n",
    "$$\n",
    "    \\underbrace{\\mathbb{E}_{x, y}\\bigl[(y - \\mathbb{E}[y|x] )^2\\bigr]}_{\\text{шум}} + \\underbrace{\\mathbb{E}_{x}\\bigl[(\\mathbb{E}_{X}[\\mu(X)(x)] - \\mathbb{E}[y|x] )^2\\bigr]}_{\\text{смещение}} +\n",
    "    \\underbrace{\\mathbb{E}_{x}\\bigl[\\mathbb{E}_{X}\\bigl[(\\mu(X)(x) - \\mathbb{E}_{X}[\\mu(X)(x)] )^2\\bigr]\\bigr]}_{\\text{разброс}},\n",
    "$$\n",
    "* $\\mu(X)$ — алгоритм, обученный по выборке $X = \\{(x_1, y_1), \\dots (x_\\ell, y_\\ell)\\}$;\n",
    "* $\\mu(X)(x)$ — ответ алгоритма, обученного по выборке $X$, на объекте $x$;\n",
    "* $\\mathbb{E}_{X}$ — мат. ожидание по всем возможным выборкам;\n",
    "* $\\mathbb{E}_{X}[\\mu(X)(x)]$ — \"средний\" ответ алгоритма, обученного по всем возможным выборкам $X$, на объекте $x$.\n",
    "    \n",
    "С помощью этой формулы мы можем анализировать свойства алгоритма обучения модели $\\mu$, если зададим вероятностную модель порождения пар $p(x, y)$.\n",
    "\n",
    "В реальных задачах мы, конечно же, не знаем распределение на парах объект - правильный ответ. Однако у нас есть набор семплов из этого распределения (обучающую выборка), и мы можем использовать его, чтобы оценивать математические ожидания. Для оценки мат. ожиданий по выборкам мы будем пользоваться бутстрэпом - методом генерации \"новых\" выборок из одной с помощью выбора объектов с возвращением. Разберем несколько шагов на пути к оценке смещения и разброса.\n",
    "\n",
    "#### Приближенное вычисление интегралов\n",
    "На занятиях мы разбирали примеры аналитического вычисления смещения и разброса нескольких алгоритмов обучения. Для большинства моделей данных и алгоритмов обучения аналитически рассчитать математические ожидания в формулах не удастся. Однако мат. ожидания можно оценивать приближенно. Чтобы оценить математическое ожидание $\\mathbb{E}_{\\bar z} f(\\bar z)$ функции от многомерной случайной величины $\\bar z = (z_1, \\dots, z_d)$, $\\bar z \\sim p(\\bar z)$, можно сгенерировать выборку из распределения $p(\\bar z)$ и усреднить значение функции на элементах этой выборки:\n",
    "$$\\mathbb{E}_{\\bar z} f(z) = \\int f(\\bar z) p(\\bar z) d \\bar z \\approx \\frac 1 m \\sum_{i=1}^m f(\\bar z_i), \\, \\bar z_i \\sim p(\\bar z), i = 1, \\dots, m.$$\n",
    "\n",
    "Например, оценим $\\mathbb{E}_z z^2,$ $z \\sim \\mathcal{N}(\\mu=5, \\sigma=3)$ (из теории вероятностей мы знаем, что\n",
    "$\\mathbb{E}_z z^2 = \\sigma^2 + \\mu^2 = 34$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.357036033750106"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.random.normal(loc=5, scale=3, size=1000)\n",
    "(z**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценивание $\\mathbb{E}_{x, y}$\n",
    "Оценить мат. ожидания по $x$ и по $x, y$, встречающиеся во всех трех компонентах разложения, несложно, потому что у нас есть выборка объектов из распределения данных $p(x, y)$:\n",
    "$$ \\mathbb{E}_{x} f(x) \\approx \\frac 1 N \\sum_{i=1}^N f(x_i), \\quad\n",
    "\\mathbb{E}_{x, y} f(x, y) \\approx \\frac 1 N \\sum_{i=1}^N f(x_i, y_i),$$\n",
    "где $N$ - число объектов в выборке, $\\{(x_i, y_i)\\}_{i=1}^N$ - сама выборка. \n",
    "\n",
    "#### Оценивание $\\mathbb{E}_X$ с помощью бутстрапа\n",
    "Чтобы оценить мат. ожидание по $X$, нам понадобится выборка из выборок:\n",
    "$$\\mathbb{E}_X f(X) \\approx \\frac 1 s \\sum_{j=1}^s f(X_j),$$\n",
    "где $X_j$ - $j$-я выборка. Чтобы их получить, мы можем воспользоваться бутстрапом - методом генерации выборок на основе выбора объектов с возвращением. Чтобы составить одну выборку, будем $N$ раз выбирать индекс объекта $i \\sim \\text{Uniform}(1 \\dots N)$ и добавлять $i$-ю пару (объект, целевая переменная) в выборку. В результате в каждой выборке могут появиться повторяющиеся объекты, а какие-то объекты могут вовсе не войти в некоторые выборки.\n",
    "\n",
    "#### Итоговый алгоритм оценки смещения и разброса алгоритма $a$\n",
    "1. Сгенерировать $s$ выборок $X_j$ методом бутстрапа.\n",
    "1. На каждой выборке $X_j$ обучить алгоритм $a_j$.\n",
    "1. Для каждой выборки $X_j$ определить множество объектов $T_j$, не вошедших в нее (out-of-bag). Вычислить предсказания алгоритма $a_j$ на объектах $T_j$. \n",
    "\n",
    "Поскольку у нас есть только один ответ для каждого объекта, мы будем считать шум равным 0, а $\\mathbb{E}[y|x]$ равным имеющемуся правильному ответу для объекта $x$. \n",
    "\n",
    "Итоговые оценки:\n",
    "* Смещение: для одного объекта - квадрат разности среднего предсказания и правильного ответа. Среднее предсказание берется только по тем алгоритмам $a_j$, для которых этот объект входил в out-of-bag выборку $T_j$. Для получения общего смещения выполнить усреденение смещений по объектам.\n",
    "* Разброс: для одного объекта - выборочная дисперсия предсказаний алгоритмов $a_j$, для которых этот объект входил в out-of-bag выборку $T_j$. Для получения общего разброса выполнить усреденение разбросов по объектам.\n",
    "* Ошибка $L$: усреднить квадраты разностей предсказания и правильного ответа по всем выполненным предсказаниям для всех объектов.\n",
    "\n",
    "В результате должно получиться, что ошибка приблизительно равна сумме смещения и разброса!\n",
    "\n",
    "Алгоритм также вкратце описан по [ссылке](https://web.engr.oregonstate.edu/~tgd/classes/534/slides/part9.pdf) (слайды 19-21).\n",
    "\n",
    "__Задание 1. (3 балла)__\n",
    "\n",
    "Реализуйте описанный алгоритм. Обратите внимание, что если объект не вошел ни в одну из out-of-bag выборок, учитывать его в вычислении итоговых величин не нужно. Как обычно, разрешается использовать только один цикл - по выборкам (от 0 до num_runs-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_biase_variance(regressor, X, y, num_runs=1000):\n",
    "    \"\"\"\n",
    "    :param regressor: sklearn estimator with fit(...) and predict(...) method\n",
    "    :param X: numpy-array representing training set ob objects, shape [n_obj, n_feat]\n",
    "    :param y: numpy-array representing target for training objects, shape [n_obj]\n",
    "    :param num_runs: int, number of samples (s in the description of the algorithm)\n",
    "    \n",
    "    :returns: bias (float), variance (float), error (float) \n",
    "    each value is computed using bootstrap\n",
    "    \"\"\"\n",
    "    preds = np.empty((num_runs, X.shape[0]))\n",
    "    preds.fill(np.nan)\n",
    "    \n",
    "    all_idx = set(np.arange(X.shape[0]))\n",
    "    for i in range(num_runs):\n",
    "        idx = np.random.randint(0, X.shape[0], X.shape[0])\n",
    "        idx_t = list(all_idx.difference(idx))\n",
    "        a = regressor.fit(X[idx], y[idx])\n",
    "        pred = regressor.predict(X[idx_t])\n",
    "        preds[i, idx_t] = pred\n",
    "        \n",
    "    \n",
    "    #смещение\n",
    "    b = np.mean((np.nanmean(preds, axis = 0) - y)**2)\n",
    "    #разброс\n",
    "    v = np.mean(np.nanmean((preds - np.nanmean(preds, axis = 0))**2, axis = 0))\n",
    "    #ошибка\n",
    "    l = np.nanmean((preds - y)**2)\n",
    "    \n",
    "    return b, v, l, b+v-l\n",
    "    \n",
    "    ### your code here ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2. (1 балл)**\n",
    "\n",
    "Оцените смещение, разброс и ошибку для трех алгоритмов с гиперпараметрами по умолчанию: линейная регрессия, решающее дерево, случайный лес.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias =  10.294122240805095 , variance =  13.0149424219365 L =  23.387853344874493 , difference =  -0.07878868213289891\n"
     ]
    }
   ],
   "source": [
    "b, v, l, diff = compute_biase_variance(DecisionTreeRegressor(), X, y)\n",
    "print(\"bias = \", b, \", variance = \", v, 'L = ', l,', difference = ', diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias =  23.745499732562234 , variance =  0.9350169396342697 L =  24.619825579620887 , difference =  0.06069109257561678\n"
     ]
    }
   ],
   "source": [
    "b, v, l, diff = compute_biase_variance(LinearRegression(), X, y)\n",
    "print(\"bias = \", b, \", variance = \", v, 'L = ', l,', difference = ', diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias =  10.691715990898091 , variance =  3.42050607111665 L =  14.157095421336985 , difference =  -0.0448733593222439\n"
     ]
    }
   ],
   "source": [
    "b, v, l, diff = compute_biase_variance(RandomForestRegressor(), X, y)\n",
    "print(\"bias = \", b, \", variance = \", v, 'L = ', l,', difference = ', diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируйте полученный результат. Согласуются ли полученные результаты с теми, что мы обсуждали на семинарах (с комментарием)?\n",
    "\n",
    "\n",
    "\n",
    "Дерево решений: небольшое смещение, большой разброс, суммарная ошибка большая\n",
    "\n",
    "Линейная регрессия: большое смещение, маленький разброс, суммарная ошибка большая\n",
    "\n",
    "Случайный лес: небольшое смещение, средний разброс, суммарная ошибка небольшая\n",
    "\n",
    "\n",
    "Небольшое смещение означает, что в среднем модель выдает правильный ответ, а небольшой разброс - что прогнозы модели мало отклоняются от среднего значения. Случайный лес обладет меньшей дисперсий по сравнению с деревом решений, так как усреднение по прогнозов непохожих деревьев, обученных на разных бутстраповских выборках, позволяет скорректировать и уменьшить дисперсии.\n",
    "\n",
    "Для случайного леса в теории дисперсия должна уменьшиться в n_estimators = 100 раз относительно одного решающего дерева, однако в эксперименте уменьшилась лишь в 3. Это может быть связано с особенностями выборки и ее небольшим размером, деревья леса могут получаться похожими, зависимыми.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация предсказаний базовых алгоритмов бэггинга\n",
    "\n",
    "В материалах лекций можно найти изображение, похожее на мишень - визуализация алгоритмов с разным смещением и разным разбросом. В центре \"мишени\" - правильный ответ, а \"попадания\" - предсказания алгоритмов, обученных по разным выборкам. Построим похожее изображение на наших данных для трех алгоритмов. Наши \"мишени\" будут одномерными, потому что мы решаем задачу одномерной регрессии.\n",
    "\n",
    "__Задание 3. (2 балла)__\n",
    "\n",
    "Реализуйте фукнцию plot_predictions. Она должна выполнять следующие действия:\n",
    "1. Случайно выбрать num_test_objects пар объект-целевая переменная из выборки X, y. Получится две выборки: маленькая X_test, y_test (выбранные тестовые объекты) и X_train, y_train (остальные объекты).\n",
    "1. Сгенерировать num_runs выборок методом бутстарапа из X_train, y_train. На каждой выборке обучить алгоритм regressor и сделать предсказания для X_test.\n",
    "1. Нарисовать scatter-график. По оси абсцисс - объекты тестовой выборки (номера от 0 до num_test_objects-1), по оси ординат - предсказания. В итоге получится num_test_objects столбиков с точками. Для каждого тестового объекта надо отметить одним цветом все предсказания для него, а также черным цветом отметить правильный ответ.\n",
    "1. Подпишите оси и название графика (аргумент title)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(regressor, X, y, num_runs=100, num_test_objects=10, title=\"\"):\n",
    "    \"\"\"\n",
    "    plot graphics described above\n",
    "    \"\"\"\n",
    "    idx = np.arange(X.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    idx_test = idx[:num_test_objects]\n",
    "    \n",
    "    X_test = X[idx_test]\n",
    "    y_test = y[idx_test]\n",
    "\n",
    "    idx_train = idx[num_test_objects:]\n",
    "    \n",
    "    X_train = X[idx_train]\n",
    "    y_train = y[idx_train]\n",
    "    \n",
    "    preds = np.zeros((num_runs, X_test.shape[0]))\n",
    "    all_idx = set(np.arange(X_train.shape[0]))\n",
    "    for i in range(num_runs):\n",
    "        idx = np.random.randint(0, X_train.shape[0], X_train.shape[0])\n",
    "        idx_t = list(all_idx.difference(idx))\n",
    "        a = regressor.fit(X_train[idx], y_train[idx])\n",
    "        pred = regressor.predict(X_test)\n",
    "        preds[i] = pred\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    ax = plt.subplot(111)\n",
    "    ax.scatter(np.arange(num_test_objects), y_test, c='black')\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        ax.scatter(np.arange(num_test_objects), preds[i], c='r')\n",
    "    ax.scatter(np.arange(num_test_objects), y_test, c='black')\n",
    "\n",
    "    ax.legend(['истинный ответ', 'предсказанный ответ'])\n",
    "    ax.set_ylabel('прогноз')\n",
    "    ax.set_xlabel('номер объекта')\n",
    "    ax.set_title(title)\n",
    "    ax.grid()\n",
    "\n",
    "\n",
    "    ### your code here ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуйте графики для линейной регрессии, решающего дерева и случайного леса. Нарисуйте три графика в строчку (это можно сделать с помощью plt.subplot) с одинаковой осью ординат (это важно для понимания масштаба разброса у разных алгоритмов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_str(regressor1,regressor2, regressor3, X, y, num_runs=100, num_test_objects=10, \n",
    "                         title1 =\"\", title2=\"\", title3=\"\"):\n",
    "    \"\"\"\n",
    "    plot graphics described above\n",
    "    \"\"\"\n",
    "    idx = np.arange(X.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    idx_test = idx[:num_test_objects]\n",
    "    \n",
    "    X_test = X[idx_test]\n",
    "    y_test = y[idx_test]\n",
    "\n",
    "    idx_train = idx[num_test_objects:]\n",
    "    \n",
    "    X_train = X[idx_train]\n",
    "    y_train = y[idx_train]\n",
    "    \n",
    "    preds1 = np.zeros((num_runs, X_test.shape[0]))\n",
    "    preds2 = np.zeros((num_runs, X_test.shape[0]))\n",
    "    preds3 = np.zeros((num_runs, X_test.shape[0]))\n",
    "\n",
    "    all_idx = set(np.arange(X_train.shape[0]))\n",
    "    for i in range(num_runs):\n",
    "        idx = np.random.randint(0, X_train.shape[0], X_train.shape[0])\n",
    "        idx_t = list(all_idx.difference(idx))\n",
    "        a = regressor1.fit(X_train[idx], y_train[idx])\n",
    "        pred = regressor1.predict(X_test)\n",
    "        preds1[i] = pred\n",
    "        \n",
    "        a = regressor2.fit(X_train[idx], y_train[idx])\n",
    "        pred = regressor2.predict(X_test)\n",
    "        preds2[i] = pred\n",
    "        \n",
    "        a = regressor3.fit(X_train[idx], y_train[idx])\n",
    "        pred = regressor3.predict(X_test)\n",
    "        preds3[i] = pred\n",
    "    \n",
    "       \n",
    "    f, (ax1, ax2, ax3) = plt.subplots(ncols = 3, nrows =1, sharey = 'all', figsize=(15, 4)) \n",
    "    \n",
    "    ax1.scatter(np.arange(num_test_objects), y_test, c='black')\n",
    "    ax2.scatter(np.arange(num_test_objects), y_test, c='black')\n",
    "    ax3.scatter(np.arange(num_test_objects), y_test, c='black')\n",
    "\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        ax1.scatter(np.arange(num_test_objects), preds1[i], c='r')\n",
    "        ax2.scatter(np.arange(num_test_objects), preds2[i], c='r')\n",
    "        ax3.scatter(np.arange(num_test_objects), preds3[i], c='r')\n",
    "    ax1.scatter(np.arange(num_test_objects), y_test, c='black')\n",
    "    ax2.scatter(np.arange(num_test_objects), y_test, c='black')\n",
    "    ax3.scatter(np.arange(num_test_objects), y_test, c='black')\n",
    "    \n",
    "    ax1.legend(['истинный ответ', 'предсказанный ответ'])\n",
    "    ax1.set_ylabel('прогноз')\n",
    "    ax1.set_xlabel('номер объекта')\n",
    "    ax1.set_title(title1)\n",
    "    ax1.grid()\n",
    "\n",
    "        \n",
    "    ax2.set_xlabel('номер объекта')\n",
    "    ax2.set_title(title2)\n",
    "    ax2.grid()\n",
    "        \n",
    "    ax3.set_xlabel('номер объекта')\n",
    "    ax3.set_title(title3)\n",
    "    ax3.grid()\n",
    "\n",
    "    ### your code here ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " plot_predictions_str(DecisionTreeRegressor(), LinearRegression(),RandomForestRegressor(),X, y,100, 10, \"Дерево решений\", \"Линейная регрессия\", \"Случайный лес\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево решений: небольшое смещение, большой разброс\n",
    "\n",
    "\n",
    "Линейная регрессия: большое смещение, маленький разброс\n",
    "\n",
    "\n",
    "Случайный лес: небольшое смещение, средний разброс\n",
    "\n",
    "\n",
    "Визуализация совпадает с ожидаемыми значениями смещения и дисперсии, посчитанными выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 2. Градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4 (1 балл)**\n",
    "\n",
    "Мы будем использовать данные из [соревнования](https://www.kaggle.com/t/b710e05dc0bd424995ca94da5b639869). \n",
    "* Загрузите таблицу application_train.csv;\n",
    "* Запишите в Y столбец с целевой переменной (TARGET);\n",
    "* Удалите ненужные столбцы (для этого воспользуйтесь описанием);\n",
    "* Определите тип столбцов и заполните пропуски - стратегия произвольная;\n",
    "* Разбейте выборку в соотношении 70:30 с random_state=0.\n",
    "\n",
    "Так как в данных имеется значительный дисбаланс классов, в качестве метрики качества везде будем использовать площадь под precision-recall кривой (AUC-PR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для категориальных признаков сделан LabelEncoding, пропусти в вещественных параметрах заполнены средним, в целочисленных - самым частым значением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"application_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215257, 122)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_CONTRACT_TYPE', 'NAME_TYPE_SUITE',\n",
    "       'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_INCOME_TYPE','NAME_HOUSING_TYPE', 'OCCUPATION_TYPE', 'WEEKDAY_APPR_PROCESS_START', \n",
    "       'ORGANIZATION_TYPE', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat:\n",
    "    data[c] = data[c].apply(lambda s:str(s))\n",
    "    data[c] = md.fit_transform(data[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['SK_ID_CURR', 'TARGET', 'FONDKAPREMONT_MODE', 'EMERGENCYSTATE_MODE', 'FLAG_CONT_MOBILE',\n",
    "          'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION'], axis = 1, inplace = True)\n",
    "#Целочисленные признаки удалены, если по описанию они принимают почти для всех объектов одинаковые значения, или много пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OWN_CAR_AGE\n",
      "YEARS_BUILD_AVG\n",
      "COMMONAREA_AVG\n",
      "FLOORSMIN_AVG\n",
      "LIVINGAPARTMENTS_AVG\n",
      "NONLIVINGAPARTMENTS_AVG\n",
      "YEARS_BUILD_MODE\n",
      "COMMONAREA_MODE\n",
      "FLOORSMIN_MODE\n",
      "LIVINGAPARTMENTS_MODE\n",
      "NONLIVINGAPARTMENTS_MODE\n",
      "YEARS_BUILD_MEDI\n",
      "COMMONAREA_MEDI\n",
      "FLOORSMIN_MEDI\n",
      "LIVINGAPARTMENTS_MEDI\n",
      "NONLIVINGAPARTMENTS_MEDI\n"
     ]
    }
   ],
   "source": [
    "for cols in data:\n",
    "    if data[cols].isna().sum() / data[cols].shape[0] * 100 >  60:\n",
    "        data.drop(cols, axis = 1, inplace = True)\n",
    "        print(cols)\n",
    "        \n",
    "#дополниетльно удалены все признаки, в которых больше 60% пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in data:\n",
    "    if data[cols].dtype  == 'int64':\n",
    "        data[cols].fillna(data[cols].value_counts().index[0], inplace = True) #самое популярнное знач\n",
    "    else:\n",
    "        data[cols].fillna(data[cols].mean(), inplace = True) #среднее\n",
    "        \n",
    "#заполнили пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_float = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215257, 49)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_float.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(data_float, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150679, 49), (150679,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5 (1 балл)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите реализации градиентного бустинга LightGBM и Catboost на вещественных признаках без подбора параметров. **Почему получилась заметная разница в качестве?**\n",
    "\n",
    "В этом и последующих экспериментах необходимо измерять время обучения моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\anaconda\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scipy in c:\\anaconda\\lib\\site-packages (from lightgbm) (1.1.0)\n",
      "Requirement already satisfied: numpy in c:\\anaconda\\lib\\site-packages (from lightgbm) (1.17.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\anaconda\\lib\\site-packages (from lightgbm) (0.19.1)\n",
      "Requirement already up-to-date: catboost==0.19.1 in c:\\users\\пользователь\\appdata\\roaming\\python\\python36\\site-packages (0.19.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy in c:\\anaconda\\lib\\site-packages (from catboost==0.19.1) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\anaconda\\lib\\site-packages (from catboost==0.19.1) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: graphviz in c:\\users\\пользователь\\appdata\\roaming\\python\\python36\\site-packages (from catboost==0.19.1) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.16.0 in c:\\anaconda\\lib\\site-packages (from catboost==0.19.1) (1.17.4)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in c:\\anaconda\\lib\\site-packages (from catboost==0.19.1) (2.2.2)\n",
      "Requirement already satisfied, skipping upgrade: plotly in c:\\users\\пользователь\\appdata\\roaming\\python\\python36\\site-packages (from catboost==0.19.1) (4.4.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=0.24.0 in c:\\users\\пользователь\\appdata\\roaming\\python\\python36\\site-packages (from catboost==0.19.1) (0.25.3)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in c:\\anaconda\\lib\\site-packages (from matplotlib->catboost==0.19.1) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib->catboost==0.19.1) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in c:\\anaconda\\lib\\site-packages (from matplotlib->catboost==0.19.1) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: pytz in c:\\anaconda\\lib\\site-packages (from matplotlib->catboost==0.19.1) (2018.4)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib->catboost==0.19.1) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: retrying>=1.3.3 in c:\\users\\пользователь\\appdata\\roaming\\python\\python36\\site-packages (from plotly->catboost==0.19.1) (1.3.3)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\anaconda\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->catboost==0.19.1) (39.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install lightgbm\n",
    "! pip install --upgrade catboost==0.19.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from time import time\n",
    "\n",
    "def time_auc_score(clf, X_train, y_train, X_test, y_test):\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    print(\"time = \", end - start)\n",
    "    pred = clf.predict(X_test)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, pred)\n",
    "    return (auc(recall, precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time =  73.23544549942017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.33951783824327997"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier \n",
    "clf = CatBoostClassifier(verbose = 0)\n",
    "time_auc_score(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time =  5.819442987442017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.37637560010155735"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from time import time\n",
    "clf = LGBMClassifier()\n",
    "time_auc_score(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметной разницы в качестве не получилось. Без подбора параметров точность классификации моделями хуже, чем у случайного классификатора. Разница во времени работы обусловлена реализацией алгоритмов: LGBM сильно оптимизирует вычислительные затраты через сокращение количества объектов и признаков выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 6. (2 балла)__\n",
    "\n",
    "Подберите оптимальные с точки зрения метрики качества параметры алгоритмов, изменяя:\n",
    "\n",
    "* глубину деревьев;\n",
    "* количество деревьев;\n",
    "* темп обучения;\n",
    "* оптимизируемый функционал.\n",
    "\n",
    "Масштаб значений предлагается посмотреть в [семинаре](https://github.com/esokolov/ml-course-hse/blob/master/2019-fall/seminars/sem10-gbm.ipynb) про библиотеки.\n",
    "\n",
    "**Проанализируйте соотношения глубины и количества деревьев в зависимости от алгоритма.** \n",
    "\n",
    "**Если на перебор гиперпараметров уходит много времени, то переберите значениях каких-нибудь 1-2 гиперпараметров, а не всех предложенных 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = [1, 5, 10, 100, 200, 300, 400, 500, 600, 700]\n",
    "depth = list(range(1, 12, 2))\n",
    "depth.append(None)\n",
    "learning_rate = np.logspace(-5, 0, 10)\n",
    "learning_rate = list(learning_rate)\n",
    "loss = ['Logloss', 'CrossEntropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "def my_custom_loss_func(y_true, y_pred):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    return auc(recall, precision)\n",
    "\n",
    "score = make_scorer(my_custom_loss_func, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_params(clf, param, X_train, y_train):\n",
    "    kf = KFold(n_splits=5)\n",
    "    cv = kf.split(X_train)\n",
    "    search = GridSearchCV(clf, param, cv = cv, scoring = score)\n",
    "    search.fit(X_train, y_train)  \n",
    "    print(search.best_params_)\n",
    "    return search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1}\n",
      "time =  1.0432116985321045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5398897457338413"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'n_estimators':n_trees}\n",
    "c = search_params(CatBoostClassifier(verbose = 0), param, X_train, y_train)\n",
    "time_auc_score(CatBoostClassifier(verbose = 0, n_estimators = c['n_estimators']), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 1}\n",
      "time =  0.6642646789550781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5398897457338413"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'max_depth':depth}\n",
    "\n",
    "c = search_params(CatBoostClassifier(verbose = 0, n_estimators = 1), param, X_train, y_train)\n",
    "time_auc_score(CatBoostClassifier(verbose = 0, n_estimators = 1, max_depth = c['max_depth']), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss_function': 'Logloss'}\n",
      "time =  0.5383603572845459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5398897457338413"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'loss_function':loss}\n",
    "\n",
    "c = search_params(CatBoostClassifier(verbose = 0, n_estimators = 1, max_depth = 1), param, X_train, y_train)\n",
    "time_auc_score(CatBoostClassifier(verbose = 0, n_estimators = 1, max_depth = 1, loss_function = c['loss_function']),\n",
    "               X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 1e-05}\n",
      "time =  0.6779425144195557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5398897457338413"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'learning_rate':learning_rate}\n",
    "c = search_params(CatBoostClassifier(verbose = 0, n_estimators = 1, max_depth = 1), param, X_train, y_train)\n",
    "time_auc_score(CatBoostClassifier(verbose = 0, n_estimators = 1, max_depth = 1, learning_rate = c['learning_rate']),\n",
    "               X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимальные гиперпараметры для CatBoost: learning rate = $10^{-5}$, n_estimators = 1, max_depth = 1, loss_function = LogLoss.\n",
    "С ними AUC = 0.54."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1}\n",
      "time =  1.1860969066619873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5398897457338413"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'n_estimators':n_trees}\n",
    "c = search_params(LGBMClassifier(verbose = 0), param, X_train, y_train)\n",
    "time_auc_score(LGBMClassifier(verbose = 0, n_estimators = c['n_estimators']), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 1}\n",
      "time =  1.1226377487182617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5398897457338413"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'max_depth':depth}\n",
    "\n",
    "c = search_params(LGBMClassifier(verbose = 0, n_estimators = 1), param, X_train, y_train)\n",
    "time_auc_score(LGBMClassifier(verbose = 0, n_estimators = 1, max_depth = c['max_depth']), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss_function': 'Logloss'}\n",
      "time =  1.0869359970092773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5398897457338413"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'loss_function':loss}\n",
    "\n",
    "c = search_params(LGBMClassifier(verbose = 0, n_estimators = 1, max_depth = 1), param, X_train, y_train)\n",
    "time_auc_score(LGBMClassifier(verbose = 0, n_estimators = 1, max_depth = 1, loss_function = c['loss_function']),\n",
    "               X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 1e-05}\n",
      "time =  1.0955135822296143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5398897457338413"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'learning_rate':learning_rate}\n",
    "c = search_params(LGBMClassifier(verbose = 0, n_estimators = 1, max_depth = 1), param, X_train, y_train)\n",
    "time_auc_score(LGBMClassifier(verbose = 0, n_estimators = 1, max_depth = 1, learning_rate = c['learning_rate']),\n",
    "               X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимальные гиперпараметры для LightGBM: learning rate = $10^{-5}$, n_estimators = 1, max_depth = 1, loss_function = LogLoss.\n",
    "С ними AUC = 0.54. Подобранные гипермапараметры и лучшее качество совпадает с соответствующими параметрами для Catboost, однако силу особенностей реализации алгоритм LightGBM работает значительно быстрее."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
